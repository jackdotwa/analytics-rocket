{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a single tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\n",
    "from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes = pd.read_csv('diabetes_csv.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This directory contain a data set prepared for the use of participants\n",
    "for the 1994 AAAI Spring Symposium on Artificial Intelligence in Medicine.\n",
    "\n",
    "768 cases, 8 variables (observation on patients who might have diabetes) and 2 classes (tested_positive or tested_negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Y is the category column and X is the matrix with all other columns\n",
    "X = df_diabetes.values[:, 0:7]\n",
    "Y = df_diabetes.values[:,8]#.astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Viewing the Classification Column mapped to values\n",
    "df_diabetes.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of unique classes (Y values)\n",
    "print(np.unique(Y))\n",
    "len(np.unique(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_max = 100 # length of matrix (number repeats)\n",
    "j_max = 50 # width of matrix (bootstrap replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err_0 is the base (without bagging)\n",
    "cases = len(df_diabetes)\n",
    "err_0 = np.zeros((i_max,1)) #ToDo just confirm\n",
    "for i in range(i_max):\n",
    "    \n",
    "    for j in range(1):\n",
    "        print(i, j, end=\"\\r\")\n",
    "        df_to_use_sample = df_diabetes\n",
    "        X = df_to_use_sample.values[:, 0:7]\n",
    "        Y = df_to_use_sample.values[:, 8]#.astype('category')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.1) # 70% training and 30% test\n",
    "        X_train = X_train.astype(float)\n",
    "        X_test = X_test.astype(float)\n",
    "        # replace missing values with rounded mean (after train/test split)\n",
    "        # https://stackoverflow.com/questions/18689235/numpy-array-replace-nan-values-with-average-of-columns\n",
    "        #col_means = np.nanmean(X_train, axis=0)\n",
    "        #inds = np.where(np.isnan(X_train))\n",
    "        #X_train[inds] = np.take(col_means, inds[1])\n",
    "        ### Rounding, because all values are categorical, not numerical\n",
    "        #col_means = np.round(np.nanmean(X_test, axis=0))\n",
    "        #inds = np.where(np.isnan(X_test))\n",
    "        #X_test[inds] = np.take(col_means, inds[1])\n",
    "        \n",
    "        # Create Decision Tree classifer object\n",
    "        clf = DecisionTreeClassifier()\n",
    "        # Train Decision Tree Classifer\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        for k in range(0,len(y_test)-1):\n",
    "            if y_test[k] != y_pred[k]:\n",
    "                err_0[i,j] = err_0[i,j] + 1\n",
    "        err_0[i,j]= err_0[i,j]/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Viewing the base\n",
    "err_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# err is the method in the paper with bagging\n",
    "cases = len(df_diabetes)\n",
    "err = np.zeros((1,j_max))\n",
    "for i in range(1):\n",
    "    \n",
    "    for j in range(j_max):\n",
    "        print(i, j, end=\"\\r\")\n",
    "        df_to_use_sample = df_diabetes.sample(n=cases, replace=True)\n",
    "        X = df_to_use_sample.values[:, 0:7]\n",
    "        Y = df_to_use_sample.values[:, 8]#.astype('category')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test\n",
    "        X_train = X_train.astype(float)\n",
    "        X_test = X_test.astype(float)\n",
    "        # replace missing values with mean (after train/test split)\n",
    "        # https://stackoverflow.com/questions/18689235/numpy-array-replace-nan-values-with-average-of-columns\n",
    "        #col_means = np.nanmean(X_train, axis=0)\n",
    "#         inds = np.where(np.isnan(X_train))\n",
    "#         X_train[inds] = np.take(col_means, inds[1])\n",
    "#         ### Rounding, because all values are categorical, not numerical\n",
    "#         col_means = np.round(np.nanmean(X_test, axis=0))\n",
    "#         inds = np.where(np.isnan(X_test))\n",
    "#         X_test[inds] = np.take(col_means, inds[1])\n",
    "        # Create RF classifer object\n",
    "        clf = RandomForestClassifier(max_depth=None, random_state=None, n_estimators=100, max_features=1, bootstrap=False)\n",
    "        # Train Decision Tree Classifer\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        for k in range(0,len(y_test)-1):\n",
    "            if y_test[k] != y_pred[k]:\n",
    "                err[i,j] = err[i,j] + 1\n",
    "        err[i,j]= err[i,j]/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# err is the method in the paper with bagging\n",
    "cases = len(df_diabetes)\n",
    "errAdaBoost = np.zeros((1,j_max))\n",
    "for i in range(1):\n",
    "    \n",
    "    for j in range(j_max):\n",
    "        print(i, j, end=\"\\r\")\n",
    "        df_to_use_sample = df_diabetes.sample(n=cases, replace=True)\n",
    "        X = df_to_use_sample.values[:, 0:7]\n",
    "        Y = df_to_use_sample.values[:, 8]#.astype('category')\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3) # 70% training and 30% test\n",
    "        X_train = X_train.astype(float)\n",
    "        X_test = X_test.astype(float)\n",
    "        # replace missing values with mean (after train/test split)\n",
    "        # https://stackoverflow.com/questions/18689235/numpy-array-replace-nan-values-with-average-of-columns\n",
    "        #col_means = np.nanmean(X_train, axis=0)\n",
    "#         inds = np.where(np.isnan(X_train))\n",
    "#         X_train[inds] = np.take(col_means, inds[1])\n",
    "#         ### Rounding, because all values are categorical, not numerical\n",
    "#         col_means = np.round(np.nanmean(X_test, axis=0))\n",
    "#         inds = np.where(np.isnan(X_test))\n",
    "#         X_test[inds] = np.take(col_means, inds[1])\n",
    "        # Create RF classifer object\n",
    "        clf = AdaBoostClassifier(random_state=None, n_estimators=100)\n",
    "        # Train Decision Tree Classifer\n",
    "        clf = clf.fit(X_train,y_train)\n",
    "        #Predict the response for test dataset\n",
    "        y_pred = clf.predict(X_test)\n",
    "        for k in range(0,len(y_test)-1):\n",
    "            if y_test[k] != y_pred[k]:\n",
    "                errAdaBoost[i,j] = errAdaBoost[i,j] + 1\n",
    "        errAdaBoost[i,j]= errAdaBoost[i,j]/len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Viewing err\n",
    "err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The paper found 23.4% for err0 and 18.8% for err, which is the improvement from bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "print(err_0.mean())\n",
    "plt.hist(err_0, bins = 60)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "print(err.mean())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(err)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(errAdaBoost.mean())\n",
    "import matplotlib.pyplot as plt\n",
    "plt.hist(errAdaBoost)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.concatenate(err_0), bins = 30)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cell_style": "split"
   },
   "outputs": [],
   "source": [
    "plt.hist(np.concatenate(err))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax1 = plt.subplots()\n",
    "ax1.hist(np.concatenate(err_0), color='tab:red', alpha=0.5, label='base - avg: {}'.format(round(err_0.mean(), 3)))\n",
    "ax1.tick_params(axis='y', labelcolor='tab:red')\n",
    "\n",
    "ax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "ax2.hist(np.concatenate(err),alpha=0.5, label='bagging - avg: {}'.format(round(err.mean(), 3)))\n",
    "ax2.tick_params(axis='y', labelcolor='tab:blue')\n",
    "\n",
    "fig.legend(loc='upper right')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
